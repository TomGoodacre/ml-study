{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3f5ee67",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b06e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = os.path.join(\"datasets\", PROJECT_ID)\n",
    "def load_data(data_path=DATA_PATH):\n",
    "    csv_path = os.path.join(titanic_data_path, \"train.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c22ba2c",
   "metadata": {},
   "source": [
    "# Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768715e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save associated data/images\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "PROJECT_ID = \"__\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", PROJECT_ID)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db28e6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0738ae",
   "metadata": {},
   "source": [
    "# Dataframe Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a320f4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a484dc73",
   "metadata": {},
   "source": [
    "### Single Column Function Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ebe369",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataframeColumnFunctionTransformer():\n",
    "    def __init__(self, func, column=None):\n",
    "        self.func = func\n",
    "        self.column = column\n",
    "\n",
    "    def transform(self, input_df, **transform_params):\n",
    "        return self.func(input_df, self.column)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "def binarize(input_df, column):\n",
    "    input_df[column] = input_df[column].notna()\n",
    "    return input_df\n",
    "\n",
    "def bool_to_int(input_df, column): \n",
    "    input_df[column] = input_df[column].map(lambda b: int(b))\n",
    "    return input_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6205fff",
   "metadata": {},
   "source": [
    "### Multiple Column Function Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998ab28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataframeMultipleColumnFunctionTransformer():\n",
    "    def __init__(self, func, columns=[]):\n",
    "        self.func = func\n",
    "        self.columns = columns\n",
    "\n",
    "    def transform(self, input_df, **transform_params):\n",
    "        return self.func(input_df, self.columns)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "def features_drop(df, columns):\n",
    "    return df.drop(columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4fef84",
   "metadata": {},
   "source": [
    "# Text Data Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a70d3f",
   "metadata": {},
   "source": [
    "### To Word Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a7d726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class WordCounterTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strip_headers=True, lower_case=True, remove_punctuation=True,\n",
    "                 replace_urls=True, replace_numbers=True, stemming=True):\n",
    "        self.strip_headers = strip_headers\n",
    "        self.lower_case = lower_case\n",
    "        self.remove_punctuation = remove_punctuation\n",
    "        self.replace_urls = replace_urls\n",
    "        self.replace_numbers = replace_numbers\n",
    "        self.stemming = stemming\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = []\n",
    "        for text in X:\n",
    "            if self.lower_case:\n",
    "                text = text.lower()\n",
    "            if self.replace_urls and url_extractor is not None:\n",
    "                urls = list(set(url_extractor.find_urls(text)))\n",
    "                urls.sort(key=lambda url: len(url), reverse=True)\n",
    "                for url in urls:\n",
    "                    text = text.replace(url, \" URL \")\n",
    "            if self.replace_numbers:\n",
    "                text = re.sub(r'\\d+(?:\\.\\d*(?:[eE]\\d+))?', 'NUMBER', text)\n",
    "            if self.remove_punctuation:\n",
    "                text = re.sub(r'\\W+', ' ', text, flags=re.M)\n",
    "            word_counts = Counter(text.split())\n",
    "            if self.stemming and stemmer is not None:\n",
    "                stemmed_word_counts = Counter()\n",
    "                for word, count in word_counts.items():\n",
    "                    stemmed_word = stemmer.stem(word)\n",
    "                    stemmed_word_counts[stemmed_word] += count\n",
    "                word_counts = stemmed_word_counts\n",
    "            X_transformed.append(word_counts)\n",
    "        return np.array(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3060fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "class WordCounterToVectorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vocabulary_size=1000):\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "    def fit(self, X, y=None):\n",
    "        total_count = Counter()\n",
    "        for word_count in X:\n",
    "            for word, count in word_count.items():\n",
    "                total_count[word] += min(count, 10)\n",
    "        most_common = total_count.most_common()[:self.vocabulary_size]\n",
    "        self.most_common_ = most_common\n",
    "        self.vocabulary_ = {word: index + 1 for index, (word, count) in enumerate(most_common)}\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        rows = []\n",
    "        cols = []\n",
    "        data = []\n",
    "        for row, word_count in enumerate(X):\n",
    "            for word, count in word_count.items():\n",
    "                rows.append(row)\n",
    "                cols.append(self.vocabulary_.get(word, 0))\n",
    "                data.append(count)\n",
    "        return csr_matrix((data, (rows, cols)), shape=(len(X), self.vocabulary_size + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871e4618",
   "metadata": {},
   "source": [
    "# Numerical stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b9246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def argmedian(x):\n",
    "  return np.argpartition(x, len(x) // 2)[len(x) // 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6313b6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
