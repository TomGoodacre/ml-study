{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14728df3",
   "metadata": {},
   "source": [
    "# Pre-flight checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9747fc",
   "metadata": {},
   "source": [
    "Import common modules, ensure MatplotLib plots figures inline, and prepare a function to save the figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8de77735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "KAGGLE_COMP_ID = \"common_lit_readability\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", KAGGLE_COMP_ID)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bd6575",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aade7d3",
   "metadata": {},
   "source": [
    "Load the data from disk (as already downloaded from kaggle website: https://www.kaggle.com/c/commonlitreadabilityprize/data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5e1164e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ntpath' from 'C:\\\\Anaconda3\\\\envs\\\\mlenv1\\\\lib\\\\ntpath.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = os.path.join(\"datasets\", KAGGLE_COMP_ID)\n",
    "def load_data(data_path=DATA_PATH):\n",
    "    csv_path = os.path.join(data_path, \"train.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc39a4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2834 entries, 0 to 2833\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   id              2834 non-null   object \n",
      " 1   url_legal       830 non-null    object \n",
      " 2   license         830 non-null    object \n",
      " 3   excerpt         2834 non-null   object \n",
      " 4   target          2834 non-null   float64\n",
      " 5   standard_error  2834 non-null   float64\n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 133.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train = load_data()\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b334861",
   "metadata": {},
   "source": [
    "<font color=blue size=4> NB: has separate test.csv, so no need to create test set</font><br>\n",
    "<font color=red size=4> NB: contains labels </font><br>\n",
    "<font color=red size=4> NB: contains standard_error for target, but how is this calculated? </font><br>\n",
    "(from website: standard_error - measure of spread of scores among multiple raters for each excerpt. Not included for test data) <br>\n",
    "<font color=red size=4> NB: url_legal & license should be irrelevant </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e38f9352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2834.000000</td>\n",
       "      <td>2834.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.959319</td>\n",
       "      <td>0.491435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.033579</td>\n",
       "      <td>0.034818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.676268</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.690320</td>\n",
       "      <td>0.468543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.912190</td>\n",
       "      <td>0.484721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.202540</td>\n",
       "      <td>0.506268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.711390</td>\n",
       "      <td>0.649671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            target  standard_error\n",
       "count  2834.000000     2834.000000\n",
       "mean     -0.959319        0.491435\n",
       "std       1.033579        0.034818\n",
       "min      -3.676268        0.000000\n",
       "25%      -1.690320        0.468543\n",
       "50%      -0.912190        0.484721\n",
       "75%      -0.202540        0.506268\n",
       "max       1.711390        0.649671"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff512e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      -0.340259\n",
       "1      -0.315372\n",
       "2      -0.580118\n",
       "3      -1.054013\n",
       "4       0.247197\n",
       "          ...   \n",
       "2829    1.711390\n",
       "2830    0.189476\n",
       "2831    0.255209\n",
       "2832   -0.215279\n",
       "2833    0.300779\n",
       "Name: target, Length: 2834, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train[\"target\"].copy()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19c3f42f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2834.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.959319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.033579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.676268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.690320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.912190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.202540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.711390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            target\n",
       "count  2834.000000\n",
       "mean     -0.959319\n",
       "std       1.033579\n",
       "min      -3.676268\n",
       "25%      -1.690320\n",
       "50%      -0.912190\n",
       "75%      -0.202540\n",
       "max       1.711390"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df = pd.DataFrame(y)\n",
    "y_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea422c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataframeMultipleColumnFunctionTransformer():\n",
    "    def __init__(self, func, columns=[]):\n",
    "        self.func = func\n",
    "        self.columns = columns\n",
    "\n",
    "    def transform(self, input_df, **transform_params):\n",
    "        return self.func(input_df, self.columns)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "def features_drop(df, columns):\n",
    "    msg = f'Dropping columns: {columns}\\n'; print(msg)\n",
    "    return df.drop(columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f295d064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping columns: ['url_legal', 'license', 'target', 'standard_error']\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2834 entries, 0 to 2833\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   id       2834 non-null   object\n",
      " 1   excerpt  2834 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 44.4+ KB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "nonfeature_columns =  [\"url_legal\", \"license\", \"target\", \"standard_error\"]\n",
    "\n",
    "preprocess_pipeline = Pipeline([\n",
    "    (\"prune_features\", DataframeMultipleColumnFunctionTransformer(features_drop, nonfeature_columns)),\n",
    "])\n",
    "\n",
    "train_preprocessed = preprocess_pipeline.fit_transform(train.copy())\n",
    "train_preprocessed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05aab917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       When the young people returned to the ballroom...\n",
       "1       All through dinner time, Mrs. Fayre was somewh...\n",
       "2       As Roger had predicted, the snow departed as q...\n",
       "3       And outside before the palace a great garden w...\n",
       "4       Once upon a time there were Three Bears who li...\n",
       "                              ...                        \n",
       "2829    When you think of dinosaurs and where they liv...\n",
       "2830    So what is a solid? Solids are usually hard be...\n",
       "2831    The second state of matter we will discuss is ...\n",
       "2832    Solids are shapes that you can actually touch....\n",
       "2833    Animals are made of many cells. They eat thing...\n",
       "Name: excerpt, Length: 2834, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text = train_preprocessed[\"excerpt\"].copy()\n",
    "train_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a275140",
   "metadata": {},
   "source": [
    "### Get some idea of what readability looks like, by looking at the passages partitioned at regular intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "311c20a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partition value: -3.676267773\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The commutator is peculiar, consisting of only three segments of a copper ring, while in the simplest of other continuous current generators several times that number exist, and frequently 120! segments are to be found. These three segments are made so as to be removable in a moment for cleaning or replacement. They are mounted upon a metal support, and are surrounded on all sides by a free air space, and cannot, therefore, lose their insulated condition. This feature of air insulation is peculiar to this system, and is very important as a factor in the durability of the commutator. Besides this, the commutator is sustained by supports carried in flanges upon the shaft, which flanges, as an additional safeguard, are coated all over with hard rubber, one of the finest known insulators. It may be stated, without fear of contradiction, that no other commutator made is so thoroughly insulated and protected. The three commutator segments virtually constitute a single copper ring, mounted in free air, and cut into three equal pieces by slots across its face.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argp = np.argmin(y)\n",
    "print(f\"partition value: {y[argp]}\\n\")\n",
    "train_text[argp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "993efd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def argpart(x, partition=0):\n",
    "  return np.argpartition(x, partition)[partition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f9b6e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partition value: -2.149327999\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Blondin, the celebrated tight-rope walker, has just died in London, at the age of seventy-three.\\nThe performance which made him famous was the crossing of Niagara Falls on the tight-rope.\\nBlondin was a Frenchman, his father having been one of Napoleon's soldiers.\\nA story is told of him that when he was five years old he saw an acrobat performing on a tight-rope.\\nHe was so pleased with what he saw, that when he got home he stretched a rope between two posts, and, as soon as his mother was out of the way, took his father's fishing-rod, and, using it as a balancing pole, made his first appearance as a tight-rope walker.\\nHe was trained for an acrobat and tight-rope walking, and came to this country with a troup of pantomimists.\\nWhile here he visited Niagara Falls, and the idea at once struck him that, if he dared to cross those terrible waters on a rope, his fortune would be made. He made up his mind to try it, and stayed in the village of Niagara for weeks, until he had learned just how it would be possible for him to perform the feat.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argp = argpart(y, partition=400)\n",
    "print(f\"partition value: {y[argp]}\\n\")\n",
    "train_text[argpart(y, partition=argp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b78beef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partition value: -1.580279588\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Looking both sides of the road, not daring to think what she would say if she really did see Clem, Polly sped on. But not a glimpse of the tall girl\\'s figure met her eyes, and at last she turned in at a gateway and ran up the little path to the door. Mrs. Forsythe saw her through the window that opened on the piazza.\\n\"Why, Polly Pepper,\" she cried, \"what a pity that Clem didn\\'t find you! She went over to your house.\"\\n\"Oh, I know, I know,\" panted Polly, with scarlet cheeks.\\n\"Don\\'t try to talk,\" said Mrs. Forsythe, \"you are all out of breath. Come in, Polly.\"\\n\"Oh, I can\\'t. I mean I would like to see Clem,\" mumbled Polly, with an awful dread, now that she was on the point of finding her, of what she should say. It was all she could do to keep from running down the piazza steps and fleeing home as fast as she had come.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argp = argpart(y, partition=800)\n",
    "print(f\"partition value: {y[argp]}\\n\")\n",
    "train_text[argpart(y, partition=argp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a5a74a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partition value: -1.136051502\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'After a time the polished rocky sides of the shaft grew to be of a solemn sameness. Clewe ceased to take notes. He tried to imagine what he would come to when he reached the bottom; it would be some sort of a cave, he thought, in which his shell had made an opening. He began to imagine what sort of a cave it would be, and how high the roof was from the floor. Clewe then suddenly wondered whether his gardener had remembered what he had told him about the flower-beds in front of the house; he wished certain changes made which Margaret had suggested. He tried to keep his mind on the flower-beds, but it drifted away to the cave below. He thought of the danger of coming into some underground body of water, where he would be drowned; but he knew that was a silly idea. If the shell had gone through subterranean reservoirs, the water of these would have run out, and before it reached the bottom of the shaft would have dissipated into mist.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argp = argpart(y, partition= 1200)\n",
    "print(f\"partition value: {y[argp]}\\n\")\n",
    "train_text[argpart(y, partition=argp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7846766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partition value: -0.73102331\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"As a statesman, it was the good fortune of Mr. Gladstone that his career was not associated with war. The reforms which he effected, the triumphs which he achieved, were not won by the supreme arbitrament of the sword. The reforms which he effected and the triumphs which he achieved were the result of his power of persuasion over his fellow-men. The reforms which he achieved in many ways amounted to a revolution. They changed, in many particulars, the face of the realm. After Sir Robert Peel had adopted the great principle which eventually carried England from protection to free trade, it was Mr. Gladstone who created the financial system which has been admitted ever since by all students of finance, as the secret of Great Britain's commercial success. He enforced the extension of the suffrage to the masses of the nation, and practically thereby made the government of monarchical England as democratic as that of any republic.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argp = argpart(y, partition=1600)\n",
    "print(f\"partition value: {y[argp]}\\n\")\n",
    "train_text[argpart(y, partition=argp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14832a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partition value: -0.349618621\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A board was floating along on the swollen waters of Black Creek. On it sat Master Meadow Mouse. He was very happy. He was having his first ride, of any sort.\\n\"This raft—\" he said to himself proudly—\"this raft belongs to me. I\\'ll be a traveler. I\\'ll see the world—at least as far as the big willow at the lower end of the meadow!\"\\nHe scarcely cared to go beyond the big willow. Beyond it lay another farm. And Master Meadow Mouse had never been off Farmer Green\\'s place in his whole life. He feared that he might not be able to find his way back, if he ventured too far from home.\\nSoon he spied a friend on the bank of the creek. Master Meadow Mouse cried, \"Goodbye!\" and waved a paw at him.\\nThe person on the bank was one of his many cousins. And when he caught sight of Master Meadow Mouse he stared hard for a few moments. Then he shouted, \"Don\\'t jump! I\\'ll rescue you.\" He was already running to the water\\'s edge when Master Meadow Mouse stopped him.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argp = argpart(y, partition=2000)\n",
    "print(f\"partition value: {y[argp]}\\n\")\n",
    "train_text[argpart(y, partition=argp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be7bb4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partition value: 0.143048465\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The Monday after the walking expedition, Grace Harlowe set out for school full of an idea that had been revolving in her busy brain for weeks. The time had come for herself and for her three chums to bind themselves together as a sorority. As charter members, they would initiate four other girls, as soon as proper rites could be thought of. It should be a Greek letter society. Grace thought \"Phi Sigma Tau\" would sound well. Aside from the social part, their chief object would be to keep a watchful eye open for girls in school who needed assistance of any sort.\\nMrs. Gray\\'s anxiety over Eleanor Savell had set the bee in Grace\\'s bonnet buzzing, and now her plans were practically perfected. All that remained to be done was to tell her three friends, and consult them as to what other four girls would be eligible to membership.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argp = argpart(y, partition=2400)\n",
    "print(f\"partition value: {y[argp]}\\n\")\n",
    "train_text[argpart(y, partition=argp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "625e028c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partition value: 1.7113898269999999\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'When you think of dinosaurs and where they lived, what do you picture? Do you see hot, steamy swamps, thick jungles, or sunny plains? Dinosaurs lived in those places, yes. But did you know that some dinosaurs lived in the cold and the darkness near the North and South Poles?\\nThis surprised scientists, too. Paleontologists used to believe that dinosaurs lived only in the warmest parts of the world. They thought that dinosaurs could only have lived in places where turtles, crocodiles, and snakes live today. Later, these dinosaur scientists began finding bones in surprising places.\\nOne of those surprising fossil beds is a place called Dinosaur Cove, Australia. One hundred million years ago, Australia was connected to Antarctica. Both continents were located near the South Pole. Today, paleontologists dig dinosaur fossils out of the ground. They think about what those ancient bones must mean.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argp = np.argmax(y)\n",
    "print(f\"partition value: {y[argp]}\\n\")\n",
    "train_text[argp]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc910b65",
   "metadata": {},
   "source": [
    "### Some initial thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f7bfa4",
   "metadata": {},
   "source": [
    "For lower scores, consider: \n",
    "- Longer sentences\n",
    "- Higher average word length\n",
    "- passive clauses\n",
    "- subordinate clauses (number of occurences of 'which'??)\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b64f1a",
   "metadata": {},
   "source": [
    "### First, see where a basic word count vector regressor gets us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3654b6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import html\n",
    "from collections import Counter\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Clean up the passage, making it ready for word counting\n",
    "class PassageTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strip_headers=True, lower_case=True, remove_punctuation=True,\n",
    "                 replace_urls=True, replace_numbers=True, remove_escapes=True):\n",
    "        self.strip_headers = strip_headers\n",
    "        self.lower_case = lower_case\n",
    "        self.remove_punctuation = remove_punctuation\n",
    "        self.replace_urls = replace_urls\n",
    "        self.replace_numbers = replace_numbers\n",
    "        self.remove_escapes = remove_escapes\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = []\n",
    "        for text in X:\n",
    "            text = html.unescape(text)\n",
    "            if self.lower_case:\n",
    "                text = text.lower()\n",
    "            if self.replace_numbers:\n",
    "                text = re.sub(r'\\d+(?:\\.\\d*(?:[eE]\\d+))?', 'NUMBER', text)\n",
    "            if self.remove_punctuation:\n",
    "                text = re.sub(r'\\W+', ' ', text, flags=re.M)\n",
    "            if self.remove_escapes:\n",
    "                text = re.sub(r\"\\n\",\" \", text)\n",
    "                text = re.sub(\"\\\\\\'\", '`', text)\n",
    "            X_transformed.append(text)\n",
    "        return np.array(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab253a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the monday after the walking expedition, grace harlowe set out for school full of an idea that had been revolving in her busy brain for weeks. the time had come for herself and for her three chums to bind themselves together as a sorority. as charter members, they would initiate four other girls, as soon as proper rites could be thought of. it should be a greek letter society. grace thought \"phi sigma tau\" would sound well. aside from the social part, their chief object would be to keep a watchful eye open for girls in school who needed assistance of any sort. mrs. gray`s anxiety over eleanor savell had set the bee in grace`s bonnet buzzing, and now her plans were practically perfected. all that remained to be done was to tell her three friends, and consult them as to what other four girls would be eligible to membership.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_clean = PassageTransformer(remove_punctuation=False).fit_transform(train_text)\n",
    "# check passage with escapes\n",
    "argp = argpart(y, partition=2400)\n",
    "X_clean[argpart(y, partition=argp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ecb3923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computations => comput\n",
      "Computation => comput\n",
      "Computing => comput\n",
      "Computed => comput\n",
      "Compute => comput\n",
      "Computator => comput\n"
     ]
    }
   ],
   "source": [
    "# Set required word class transformers\n",
    "import nltk\n",
    "\n",
    "stemmer = nltk.PorterStemmer()\n",
    "# and test\n",
    "for word in (\"Computations\", \"Computation\", \"Computing\", \"Computed\", \"Compute\", \"Computator\"):\n",
    "    print(word, \"=>\", stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd35f580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class WordCounterTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, stemming=True):\n",
    "        self.stemming = stemming\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = []\n",
    "        for text in X:\n",
    "            word_counts = Counter(text.split())\n",
    "            if self.stemming and stemmer is not None:\n",
    "                stemmed_word_counts = Counter()\n",
    "                for word, count in word_counts.items():\n",
    "                    stemmed_word = stemmer.stem(word)\n",
    "                    stemmed_word_counts[stemmed_word] += count\n",
    "                word_counts = stemmed_word_counts\n",
    "            X_transformed.append(word_counts)\n",
    "        return np.array(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9be3108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['when the young people returned to the ballroom, it presented a decidedly changed appearance. instead of an interior scene, it was a winter landscape. the floor was covered with snow-white canvas, not laid on smoothly, but rumpled over bumps and hillocks, like a real snow field. the numerous palms and evergreens that had decorated the room, were powdered with flour and strewn with tufts of cotton, like snow. also diamond dust had been lightly sprinkled on them, and glittering crystal icicles hung from the branches. at each end of the room, on the wall, hung a beautiful bear-skin rug. these rugs were for prizes, one for the girls and one for the boys. and this was the game. the girls were gathered at one end of the room and the boys at the other, and one end was called the north pole, and the other the south pole. each player was given a small flag which they were to plant on reaching the pole. this would have been an easy matter, but each traveller was obliged to wear snowshoes.',\n",
       "       'all through dinner time, mrs. fayre was somewhat silent, her eyes resting on dolly with a wistful, uncertain expression. she wanted to give the child the pleasure she craved, but she had hard work to bring herself to the point of overcoming her own objections. at last, however, when the meal was nearly over, she smiled at her little daughter, and said, \"all right, dolly, you may go.\" \"oh, mother!\" dolly cried, overwhelmed with sudden delight. \"really? oh, i am so glad! are you sure you`re willing?\" \"i`ve persuaded myself to be willing, against my will,\" returned mrs. fayre, whimsically. \"i confess i just hate to have you go, but i can`t bear to deprive you of the pleasure trip. and, as you say, it would also keep dotty at home, and so, altogether, i think i shall have to give in.\" \"oh, you angel mother! you blessed lady! how good you are!\" and dolly flew around the table and gave her mother a hug that nearly suffocated her.',\n",
       "       'as roger had predicted, the snow departed as quickly as it came, and two days after their sleigh ride there was scarcely a vestige of white on the ground. tennis was again possible and a great game was in progress on the court at pine laurel. patty and roger were playing against elise and sam blaney, and the pairs were well matched. but the long-contested victory finally went against patty, and she laughingly accepted defeat. \"only because patty`s not quite back on her game yet,\" roger defended; \"this child has been on the sick list, you know, sam, and she isn`t up to her own mark.\" \"well, i like that!\" cried patty; \"suppose you bear half the blame, roger. you see, mr. blaney, he is so absorbed in his own love game, he can`t play with his old-time skill.\" \"all right, patsy, let it go at that. and it`s so, too. i suddenly remembered something mona told me to tell you, and it affected my service.\"'],\n",
       "      dtype='<U1361')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_few = X_clean[:3]\n",
    "X_few"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d606b1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Counter({'the': 19, 'and': 9, 'wa': 6, 'a': 5, 'of': 4, 'on': 4, 'were': 4, 'one': 4, 'to': 3, 'with': 3, 'at': 3, 'each': 3, 'end': 3, 'for': 3, 'it': 2, 'an': 2, 'but': 2, 'like': 2, 'had': 2, 'room,': 2, 'been': 2, 'hung': 2, 'girl': 2, 'thi': 2, 'pole.': 2, 'when': 1, 'young': 1, 'peopl': 1, 'return': 1, 'ballroom,': 1, 'present': 1, 'decidedli': 1, 'chang': 1, 'appearance.': 1, 'instead': 1, 'interior': 1, 'scene,': 1, 'winter': 1, 'landscape.': 1, 'floor': 1, 'cover': 1, 'snow-whit': 1, 'canvas,': 1, 'not': 1, 'laid': 1, 'smoothly,': 1, 'rumpl': 1, 'over': 1, 'bump': 1, 'hillocks,': 1, 'real': 1, 'snow': 1, 'field.': 1, 'numer': 1, 'palm': 1, 'evergreen': 1, 'that': 1, 'decor': 1, 'powder': 1, 'flour': 1, 'strewn': 1, 'tuft': 1, 'cotton,': 1, 'snow.': 1, 'also': 1, 'diamond': 1, 'dust': 1, 'lightli': 1, 'sprinkl': 1, 'them,': 1, 'glitter': 1, 'crystal': 1, 'icicl': 1, 'from': 1, 'branches.': 1, 'wall,': 1, 'beauti': 1, 'bear-skin': 1, 'rug.': 1, 'these': 1, 'rug': 1, 'prizes,': 1, 'boys.': 1, 'game.': 1, 'gather': 1, 'room': 1, 'boy': 1, 'other,': 1, 'call': 1, 'north': 1, 'pole,': 1, 'other': 1, 'south': 1, 'player': 1, 'given': 1, 'small': 1, 'flag': 1, 'which': 1, 'they': 1, 'plant': 1, 'reach': 1, 'would': 1, 'have': 1, 'easi': 1, 'matter,': 1, 'travel': 1, 'oblig': 1, 'wear': 1, 'snowshoes.': 1}),\n",
       "       Counter({'you': 8, 'to': 7, 'the': 6, 'i': 5, 'her': 4, 'she': 4, 'and': 4, 'dolli': 3, 'at': 3, 'mrs.': 2, 'wa': 2, 'with': 2, 'a': 2, 'give': 2, 'pleasur': 2, 'but': 2, 'of': 2, 'nearli': 2, '\"oh,': 2, 'have': 2, 'all': 1, 'through': 1, 'dinner': 1, 'time,': 1, 'fayr': 1, 'somewhat': 1, 'silent,': 1, 'eye': 1, 'rest': 1, 'on': 1, 'wistful,': 1, 'uncertain': 1, 'expression.': 1, 'want': 1, 'child': 1, 'craved,': 1, 'had': 1, 'hard': 1, 'work': 1, 'bring': 1, 'herself': 1, 'point': 1, 'overcom': 1, 'own': 1, 'objections.': 1, 'last,': 1, 'however,': 1, 'when': 1, 'meal': 1, 'over,': 1, 'smile': 1, 'littl': 1, 'daughter,': 1, 'said,': 1, '\"all': 1, 'right,': 1, 'dolly,': 1, 'may': 1, 'go.\"': 1, 'mother!\"': 1, 'cried,': 1, 'overwhelm': 1, 'sudden': 1, 'delight.': 1, '\"really?': 1, 'oh,': 1, 'am': 1, 'so': 1, 'glad!': 1, 'are': 1, 'sure': 1, 'you`r': 1, 'willing?\"': 1, '\"i`v': 1, 'persuad': 1, 'myself': 1, 'be': 1, 'willing,': 1, 'against': 1, 'my': 1, 'will,\"': 1, 'return': 1, 'fayre,': 1, 'whimsically.': 1, '\"i': 1, 'confess': 1, 'just': 1, 'hate': 1, 'go,': 1, 'can`t': 1, 'bear': 1, 'depriv': 1, 'trip.': 1, 'and,': 1, 'as': 1, 'say,': 1, 'it': 1, 'would': 1, 'also': 1, 'keep': 1, 'dotti': 1, 'home,': 1, 'so,': 1, 'altogether,': 1, 'think': 1, 'shall': 1, 'in.\"': 1, 'angel': 1, 'mother!': 1, 'bless': 1, 'lady!': 1, 'how': 1, 'good': 1, 'are!\"': 1, 'flew': 1, 'around': 1, 'tabl': 1, 'gave': 1, 'mother': 1, 'hug': 1, 'that': 1, 'suffoc': 1, 'her.': 1}),\n",
       "       Counter({'and': 9, 'the': 7, 'on': 4, 'as': 3, 'roger': 3, 'it': 3, 'wa': 3, 'you': 3, 'a': 2, 'game': 2, 'in': 2, 'at': 2, 'were': 2, 'play': 2, 'against': 2, 'blaney,': 2, 'she': 2, 'her': 2, 'to': 2, 'own': 2, 'i': 2, 'he': 2, 'hi': 2, 'had': 1, 'predicted,': 1, 'snow': 1, 'depart': 1, 'quickli': 1, 'came,': 1, 'two': 1, 'day': 1, 'after': 1, 'their': 1, 'sleigh': 1, 'ride': 1, 'there': 1, 'scarc': 1, 'vestig': 1, 'of': 1, 'white': 1, 'ground.': 1, 'tenni': 1, 'again': 1, 'possibl': 1, 'great': 1, 'progress': 1, 'court': 1, 'pine': 1, 'laurel.': 1, 'patti': 1, 'elis': 1, 'sam': 1, 'pair': 1, 'well': 1, 'matched.': 1, 'but': 1, 'long-contest': 1, 'victori': 1, 'final': 1, 'went': 1, 'patty,': 1, 'laughingli': 1, 'accept': 1, 'defeat.': 1, '\"onli': 1, 'becaus': 1, 'patty`': 1, 'not': 1, 'quit': 1, 'back': 1, 'yet,\"': 1, 'defended;': 1, '\"thi': 1, 'child': 1, 'ha': 1, 'been': 1, 'sick': 1, 'list,': 1, 'know,': 1, 'sam,': 1, 'isn`t': 1, 'up': 1, 'mark.\"': 1, '\"well,': 1, 'like': 1, 'that!\"': 1, 'cri': 1, 'patty;': 1, '\"suppos': 1, 'bear': 1, 'half': 1, 'blame,': 1, 'roger.': 1, 'see,': 1, 'mr.': 1, 'is': 1, 'so': 1, 'absorb': 1, 'love': 1, 'game,': 1, 'can`t': 1, 'with': 1, 'old-tim': 1, 'skill.\"': 1, '\"all': 1, 'right,': 1, 'patsy,': 1, 'let': 1, 'go': 1, 'that.': 1, 'it`': 1, 'so,': 1, 'too.': 1, 'suddenli': 1, 'rememb': 1, 'someth': 1, 'mona': 1, 'told': 1, 'me': 1, 'tell': 1, 'you,': 1, 'affect': 1, 'my': 1, 'service.\"': 1})],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_few_wordcounts = WordCounterTransformer().fit_transform(X_few)\n",
    "X_few_wordcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cce12793",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "class WordCounterToVectorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vocabulary_size=1000):\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "    def fit(self, X, y=None):\n",
    "        total_count = Counter()\n",
    "        for word_count in X:\n",
    "            for word, count in word_count.items():\n",
    "                total_count[word] += min(count, 10)\n",
    "        most_common = total_count.most_common()[:self.vocabulary_size]\n",
    "        self.most_common_ = most_common\n",
    "        self.vocabulary_ = {word: index + 1 for index, (word, count) in enumerate(most_common)}\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        rows = []\n",
    "        cols = []\n",
    "        data = []\n",
    "        for row, word_count in enumerate(X):\n",
    "            for word, count in word_count.items():\n",
    "                rows.append(row)\n",
    "                cols.append(self.vocabulary_.get(word, 0))\n",
    "                data.append(count)\n",
    "        return csr_matrix((data, (rows, cols)), shape=(len(X), self.vocabulary_size + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9280385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 19,  9,  3,  6,  0,  5,  4,  3,  4,  0,  2,  3,  4,  0,  0,\n",
       "         2,  2,  4,  0,  2,  2,  3,  3,  3,  1,  0,  0,  0,  0,  1,  1,\n",
       "         2,  1,  1,  1,  2,  1,  2,  2,  2,  2,  1,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  6,  4,  7,  2,  8,  2,  1,  3,  2,  5,  1,  2,  0,  4,  4,\n",
       "         2,  1,  0,  1,  0,  0,  0,  0,  0,  2,  3,  1,  1,  0,  1,  1,\n",
       "         0,  0,  0,  1,  0,  1,  0,  0,  0,  0,  1,  2,  2,  1,  2,  2,\n",
       "         1,  1,  2,  1,  1,  1,  1,  1,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 6,  7,  9,  2,  3,  3,  2,  4,  2,  1,  2,  3,  1,  2,  2,  2,\n",
       "         1,  1,  0,  3,  1,  1,  0,  0,  0,  0,  0,  2,  2,  3,  0,  0,\n",
       "         0,  1,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,\n",
       "         1,  1,  0,  1,  1,  1,  1,  1,  2,  2,  2,  2,  2,  2,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1]], dtype=int32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_vector_trans = WordCounterToVectorTransformer(vocabulary_size=300)\n",
    "X_few_word_vectors = to_vector_trans.fit_transform(X_few_wordcounts)\n",
    "X_few_word_vectors.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "faaa713e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2834x301 sparse matrix of type '<class 'numpy.intc'>'\n",
       "\twith 143063 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_pipeline = Pipeline([\n",
    "    (\"word_counter\", WordCounterTransformer()),\n",
    "    (\"to_vectors\", to_vector_trans)\n",
    "])\n",
    "\n",
    "X_vector = preprocess_pipeline.fit_transform(X_clean)\n",
    "X_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "174b0ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2834, 301)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f5a1a265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'and': 2,\n",
       " 'of': 3,\n",
       " 'to': 4,\n",
       " 'a': 5,\n",
       " 'in': 6,\n",
       " 'wa': 7,\n",
       " 'is': 8,\n",
       " 'it': 9,\n",
       " 'that': 10,\n",
       " 'he': 11,\n",
       " 'as': 12,\n",
       " 'for': 13,\n",
       " 'with': 14,\n",
       " 'hi': 15,\n",
       " 'on': 16,\n",
       " 'they': 17,\n",
       " 'be': 18,\n",
       " 'had': 19,\n",
       " 'are': 20,\n",
       " 'at': 21,\n",
       " 'not': 22,\n",
       " 'by': 23,\n",
       " 'i': 24,\n",
       " 'but': 25,\n",
       " 'from': 26,\n",
       " 'thi': 27,\n",
       " 'she': 28,\n",
       " 'have': 29,\n",
       " 'were': 30,\n",
       " 'or': 31,\n",
       " 'which': 32,\n",
       " 'her': 33,\n",
       " 'one': 34,\n",
       " 'you': 35,\n",
       " 'all': 36,\n",
       " 'when': 37,\n",
       " 'their': 38,\n",
       " 'so': 39,\n",
       " 'an': 40,\n",
       " 'we': 41,\n",
       " 'there': 42,\n",
       " 'can': 43,\n",
       " 'veri': 44,\n",
       " 'would': 45,\n",
       " 'littl': 46,\n",
       " 'into': 47,\n",
       " 'number': 48,\n",
       " 'been': 49,\n",
       " 'up': 50,\n",
       " 'out': 51,\n",
       " 'use': 52,\n",
       " 'some': 53,\n",
       " 'other': 54,\n",
       " 'ha': 55,\n",
       " 'will': 56,\n",
       " 'about': 57,\n",
       " 'who': 58,\n",
       " 'like': 59,\n",
       " 'if': 60,\n",
       " 'my': 61,\n",
       " 'could': 62,\n",
       " 'no': 63,\n",
       " 'him': 64,\n",
       " 'what': 65,\n",
       " 'more': 66,\n",
       " 'then': 67,\n",
       " 'these': 68,\n",
       " 'them': 69,\n",
       " 'call': 70,\n",
       " 'do': 71,\n",
       " 'make': 72,\n",
       " 'than': 73,\n",
       " 'two': 74,\n",
       " 'said': 75,\n",
       " 'made': 76,\n",
       " 'time': 77,\n",
       " 'mani': 78,\n",
       " 'great': 79,\n",
       " 'our': 80,\n",
       " 'look': 81,\n",
       " 'over': 82,\n",
       " 'onli': 83,\n",
       " 'peopl': 84,\n",
       " 'go': 85,\n",
       " 'such': 86,\n",
       " 'after': 87,\n",
       " 'come': 88,\n",
       " 'first': 89,\n",
       " 'where': 90,\n",
       " 'came': 91,\n",
       " 'most': 92,\n",
       " 'how': 93,\n",
       " 'also': 94,\n",
       " 'see': 95,\n",
       " 'did': 96,\n",
       " 'went': 97,\n",
       " 'your': 98,\n",
       " 'down': 99,\n",
       " 'get': 100,\n",
       " 'ani': 101,\n",
       " 'old': 102,\n",
       " 'day': 103,\n",
       " 'much': 104,\n",
       " 'through': 105,\n",
       " 'differ': 106,\n",
       " 'everi': 107,\n",
       " 'upon': 108,\n",
       " 'may': 109,\n",
       " 'even': 110,\n",
       " 'long': 111,\n",
       " 'live': 112,\n",
       " 'water': 113,\n",
       " 'good': 114,\n",
       " 'way': 115,\n",
       " 'while': 116,\n",
       " 'befor': 117,\n",
       " 'now': 118,\n",
       " 'take': 119,\n",
       " 'new': 120,\n",
       " 'becaus': 121,\n",
       " 'year': 122,\n",
       " 'just': 123,\n",
       " 'work': 124,\n",
       " 'each': 125,\n",
       " 'found': 126,\n",
       " 'know': 127,\n",
       " 'must': 128,\n",
       " 'part': 129,\n",
       " 'thing': 130,\n",
       " 'place': 131,\n",
       " 'man': 132,\n",
       " 'me': 133,\n",
       " 'those': 134,\n",
       " 'think': 135,\n",
       " 'back': 136,\n",
       " 'put': 137,\n",
       " 'between': 138,\n",
       " 'saw': 139,\n",
       " 'should': 140,\n",
       " 'never': 141,\n",
       " '\"i': 142,\n",
       " 'still': 143,\n",
       " 'it.': 144,\n",
       " 'thought': 145,\n",
       " 'same': 146,\n",
       " 'want': 147,\n",
       " 'without': 148,\n",
       " 'give': 149,\n",
       " 'help': 150,\n",
       " 'seem': 151,\n",
       " 'three': 152,\n",
       " 'under': 153,\n",
       " 'form': 154,\n",
       " 'larg': 155,\n",
       " 'mean': 156,\n",
       " 'own': 157,\n",
       " 'well': 158,\n",
       " 'turn': 159,\n",
       " 'brain': 160,\n",
       " 'find': 161,\n",
       " 'around': 162,\n",
       " 'boy': 163,\n",
       " 'us': 164,\n",
       " 'soon': 165,\n",
       " 'began': 166,\n",
       " 'took': 167,\n",
       " 'ask': 168,\n",
       " 'might': 169,\n",
       " 'play': 170,\n",
       " 'open': 171,\n",
       " 'alway': 172,\n",
       " 'often': 173,\n",
       " 'state': 174,\n",
       " 'last': 175,\n",
       " 'small': 176,\n",
       " 'off': 177,\n",
       " 'said,': 178,\n",
       " 'onc': 179,\n",
       " 'anoth': 180,\n",
       " 'and,': 181,\n",
       " 'too': 182,\n",
       " 'away': 183,\n",
       " 'need': 184,\n",
       " 'young': 185,\n",
       " 'big': 186,\n",
       " 'light': 187,\n",
       " 'quit': 188,\n",
       " 'gener': 189,\n",
       " 'carri': 190,\n",
       " 'few': 191,\n",
       " 'however,': 192,\n",
       " 'it,': 193,\n",
       " 'name': 194,\n",
       " 'mother': 195,\n",
       " 'hous': 196,\n",
       " 'set': 197,\n",
       " 'chang': 198,\n",
       " 'mr.': 199,\n",
       " 'number,': 200,\n",
       " 'got': 201,\n",
       " 'them.': 202,\n",
       " 'him.': 203,\n",
       " 'until': 204,\n",
       " 'him,': 205,\n",
       " 'say': 206,\n",
       " 'dure': 207,\n",
       " 'human': 208,\n",
       " 'tell': 209,\n",
       " 'import': 210,\n",
       " 'known': 211,\n",
       " 'tri': 212,\n",
       " 'both': 213,\n",
       " 'start': 214,\n",
       " 'children': 215,\n",
       " 'studi': 216,\n",
       " 'pass': 217,\n",
       " 'told': 218,\n",
       " 'home': 219,\n",
       " 'show': 220,\n",
       " 'side': 221,\n",
       " 'here': 222,\n",
       " 'hand': 223,\n",
       " 'almost': 224,\n",
       " 'anim': 225,\n",
       " 'eye': 226,\n",
       " 'men': 227,\n",
       " 'walk': 228,\n",
       " 'far': 229,\n",
       " 'left': 230,\n",
       " 'himself': 231,\n",
       " 'though': 232,\n",
       " 'leav': 233,\n",
       " 'reach': 234,\n",
       " 'word': 235,\n",
       " 'sever': 236,\n",
       " 'white': 237,\n",
       " 'move': 238,\n",
       " 'person': 239,\n",
       " 'right': 240,\n",
       " 'countri': 241,\n",
       " 'learn': 242,\n",
       " 'tree': 243,\n",
       " 'against': 244,\n",
       " 'cell': 245,\n",
       " 'let': 246,\n",
       " 'power': 247,\n",
       " 'run': 248,\n",
       " 'gave': 249,\n",
       " 'knew': 250,\n",
       " 'kind': 251,\n",
       " 'end': 252,\n",
       " 'keep': 253,\n",
       " 'heard': 254,\n",
       " 'world': 255,\n",
       " 'natur': 256,\n",
       " 'becam': 257,\n",
       " 'king': 258,\n",
       " 'life': 259,\n",
       " 'girl': 260,\n",
       " 'head': 261,\n",
       " 'becom': 262,\n",
       " 'along': 263,\n",
       " 'love': 264,\n",
       " 'someth': 265,\n",
       " 'caus': 266,\n",
       " 'follow': 267,\n",
       " 'am': 268,\n",
       " 'war': 269,\n",
       " 'noth': 270,\n",
       " 'seen': 271,\n",
       " 'eat': 272,\n",
       " 'father': 273,\n",
       " 'close': 274,\n",
       " 'near': 275,\n",
       " 'beauti': 276,\n",
       " 'sun': 277,\n",
       " 'plant': 278,\n",
       " 'ever': 279,\n",
       " 'feel': 280,\n",
       " 'time,': 281,\n",
       " 'high': 282,\n",
       " 'next': 283,\n",
       " 'sometim': 284,\n",
       " 'red': 285,\n",
       " 'care': 286,\n",
       " 'system': 287,\n",
       " 'whole': 288,\n",
       " 'four': 289,\n",
       " 'includ': 290,\n",
       " 'sat': 291,\n",
       " 'hard': 292,\n",
       " 'face': 293,\n",
       " 'point': 294,\n",
       " 'bird': 295,\n",
       " 'doe': 296,\n",
       " 'among': 297,\n",
       " 'unit': 298,\n",
       " 'sinc': 299,\n",
       " 'dog': 300}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_vector_trans.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c182f4c0",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- process further with word relevance with tf-idf etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713d778f",
   "metadata": {},
   "source": [
    "# Try some simple regression training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01c168b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "    \n",
    "def rough_score(model):\n",
    "    scores = cross_val_score(model, X_vector, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    rmse_scores = np.sqrt(-scores)\n",
    "    display_scores(rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3805aaee",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ca52391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.72694971 0.8302842  0.86237999 0.92107784 0.70845068 0.79678526\n",
      " 0.82555318 0.84382759 0.70902002 0.75689229]\n",
      "Mean: 0.7981220749545953\n",
      "Standard deviation: 0.06772767796173992\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model_lin_reg = Ridge()\n",
    "rough_score(model_lin_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0210e0ca",
   "metadata": {},
   "source": [
    "### RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e544442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.7175718  0.8253037  0.90773836 0.92764329 0.7888376  0.87455935\n",
      " 0.85325812 0.88207377 0.7113172  0.83213016]\n",
      "Mean: 0.8320433344786782\n",
      "Standard deviation: 0.07015732836642817\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model_forest = RandomForestRegressor(random_state=42)\n",
    "rough_score(model_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ecb64e",
   "metadata": {},
   "source": [
    "### Conclusion 1\n",
    "For such a simple approach, better than expected... (less than 20% of the range, so better than random at least)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb389d61",
   "metadata": {},
   "source": [
    "## Try a different approach, engineering whole-passage features and combining them with the word vector prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac40fd0",
   "metadata": {},
   "source": [
    "A paper on readability features: https://www.aclweb.org/anthology/2020.bea-1.1.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d7d807",
   "metadata": {},
   "source": [
    "### TODO\n",
    "First features to capture:\n",
    "- Longer sentences\n",
    "- passive clauses\n",
    "- subordinate clauses (number of occurences of 'which'??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7a0604d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add average word size feature\n",
    "\n",
    "def average_word_size_feature(X, y=None):\n",
    "    word_size_count = 0\n",
    "    word_count = 0\n",
    "    word_count_array = []\n",
    "    for text in X:\n",
    "        for word in text.split():\n",
    "            word_size_count = word_size_count + len(word)\n",
    "            word_count = word_count + 1\n",
    "        word_count_array.append(word_size_count / word_count)\n",
    "    return np.array(word_count_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9892b89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0f989f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"avg_word_size\"] = average_word_size_feature(X_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "198fa4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2834 entries, 0 to 2833\n",
      "Data columns (total 1 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   avg_word_size  2834 non-null   float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 22.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "18d26112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_word_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2834.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.702050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.113658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.368753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.655808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.724962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.779325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.857056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       avg_word_size\n",
       "count    2834.000000\n",
       "mean        4.702050\n",
       "std         0.113658\n",
       "min         4.368753\n",
       "25%         4.655808\n",
       "50%         4.724962\n",
       "75%         4.779325\n",
       "max         4.857056"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c815bb",
   "metadata": {},
   "source": [
    "#### Note: range ~ 0.5, perhaps not so relevant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b1c50e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
